1. What is Generative AI and how does its architecture work? Architecture of Generative AI:
2. What is the difference between Traditional AI and Generative AI?
3. How does Generative AI differ from Agentic AI?
4. What is the Encoder-Decoder Model in AI?
5. What are Autoencoders and how do they work?
6. What is a Variational Autoencoder (VAE)? How does it differ from a standard autoencoder?
7. Explain the concept of Context Window in LLMs.
8. What is Memory in LLMs and how is it implemented in agentic systems?
9. What is Tokenization and why is it important for LLMs?
10. What are Embeddings and how do they capture semantic meaning?
11. Compare different types of Embedding Databases
12. What are the use cases of Vector Databases in RAG pipelines?
13. What is LLM Distillation and why is it used?
14. What is Hugging Face and what are its main use cases?
15. What is the Model Hub, Model Card and Dataset Hub on Hugging Face?
16.  What is LangChain and what problem does it solve?
17. Explain LangGraph and how it enhances agentic workflows.
18. Explain RAG (Retrieval-Augmented Generation) architecture in detail.
19. What is the role of Vector Stores in a RAG pipeline?
20. Explain different types of prompting.
21. smart grid 2.0 , criticality.